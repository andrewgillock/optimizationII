{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Modified National Institute of Standards and Technology (MNIST) dataset is a large database composed of images of handwritten digits. Each 'image' is a 28x28 dataframe containing single grayscale values in each element of the matrix. This database is frequently used to understand image classification machine learning models through pattern recognition. The goal of this project is to design a convolutional neural network that classifies the MNIST test dataset with 99% or greater accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize grayscale values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "ndata_train = x_train.shape[0] # = 60000\n",
    "ndata_test = x_test.shape[0] # = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow requires us to include 3rd dimension for color (1)\n",
    "x_train2 = x_train.reshape((ndata_train,28,28,1))\n",
    "x_test2 = x_test.reshape((ndata_test,28,28,1))\n",
    "\n",
    "xshape = x_train2.shape[1:4] # we only need the image dimensions for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "\n",
    "Convolutional neural networks (CNNs) are often used in networks that take images as input. They work by applying a set of filters to the image, which can be thought of as a small subset of the original photo. Similarity scores (the dot product of filter and that portion of the image) are computed between the filter and image as the filter is moved across different positions in the image. An example of a filter is seen below in Figure 1.\n",
    "\n",
    "The application of filters results in significantly more data which can increase processing times for the network. In order to 'fix' this problem, we can introduce a max pooling layer, which functions similar to a filter. The max pool filter moves across the similarity score matrix, but rather than computing the dot product, the largest value within the filter is used to define that whole section of similarity. As a result, we decrease the number of input neurons required by the dense neural network and identify the general vicinity of corresponding filter-image similarities. The output of the max pool layer is passed into a dense neural network to complete the classification. The final output of the model is a vector of 10 probabilities, one for each digit 0-9. The index with the largest probability is the number predicted by the network. A visualization of this process can be seen below in Figure 2.\n",
    "\n",
    "Using this information, we now develop our own CNN with the goal of achieving 99% or greater classification accuracy on the MNIST test dataset. We began this process by fitting different combinations of convolution and max pool layers to the training set of 60,000 images. A validation split of 0.2 was used to prevent overfitting of the model. For the convolutional layers, we found that 2 layers of small filters, a max pool layer, another convolutional layer, and a final max pool layer present us with the largest validation accuracy. The first convolutional layer is composed of 20 5x5 filters and a ReLU activation. The second convolutional layer has 20 2x2 filters and a ReLU activation. The first max pool layer uses a pool size of 2x2 with a stride of 2 to prevent overlap. The final convolutional layer contains 50 2x2 filters and a ReLU activation. The final max pool layer once again uses a pool size of 2x2 and a stride of 2. The output of the final max pool layer is fed into multiple dense and dropout layers before outputting the final classification of the image. Once the model achieved greater than 99% validation accuracy, we retrained the same model using the entire training set.  A summary of our group's model can be seen below in Figure 3.  Additionally, Figure 4 displays a completed CNN similar to our own, which helps with a visualization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel = tf.keras.models.Sequential()\n",
    "NNmodel.add(tf.keras.layers.Conv2D(filters = 20, kernel_size = (5,5), activation = tf.nn.relu, input_shape = xshape))\n",
    "NNmodel.add(tf.keras.layers.Conv2D(filters = 20, kernel_size = (2,2), activation = tf.nn.relu))\n",
    "NNmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2))\n",
    "NNmodel.add(tf.keras.layers.Conv2D(filters = 50, kernel_size = (2,2), activation = tf.nn.relu))\n",
    "NNmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2))\n",
    "NNmodel.add(tf.keras.layers.Flatten())\n",
    "NNmodel.add(tf.keras.layers.Dropout(rate = 0.4))\n",
    "NNmodel.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "NNmodel.add(tf.keras.layers.Dropout(rate = 0.2))\n",
    "NNmodel.add(tf.keras.layers.Dense(64,activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l1(0.0005)))\n",
    "NNmodel.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 24, 24, 20)        520       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 23, 23, 20)        1620      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 11, 11, 20)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 10, 10, 50)        4050      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1250)              0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               160128    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,224\n",
      "Trainable params: 175,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# NNmodel.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to re-run, model coefficients are stored\n",
    "\n",
    "# fit model to entire training set\n",
    "# NNmodel.fit(x_train2,y_train,epochs=20,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 15ms/step - loss: 2.6670 - accuracy: 0.1060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.667048215866089, 0.10599999874830246]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on MNIST test set\n",
    "NNmodel.evaluate(x_test2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract classified and misclassified image indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 20)        520       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 23, 23, 20)        1620      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 11, 11, 20)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 50)        4050      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1250)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1250)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               160128    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,224\n",
      "Trainable params: 175,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reload saved model\n",
    "new_model = tf.keras.models.load_model('my_model')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 25ms/step - loss: 0.0414 - accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04142482578754425, 0.9934999942779541]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that saved model yields same results on MNIST test set\n",
    "new_model.evaluate(x_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0668310e-10, 5.1234097e-06, 1.9271326e-06, ..., 9.9998558e-01,\n",
       "        9.4626749e-08, 5.5025171e-06],\n",
       "       [1.6515084e-09, 1.5389305e-07, 9.9999988e-01, ..., 3.1046592e-11,\n",
       "        5.8142628e-09, 8.2657351e-13],\n",
       "       [2.2984310e-08, 9.9993062e-01, 2.9836983e-06, ..., 4.2366764e-06,\n",
       "        1.7984901e-06, 1.6960884e-07],\n",
       "       ...,\n",
       "       [3.4410442e-15, 4.7695217e-08, 3.5074996e-12, ..., 2.7821939e-10,\n",
       "        1.4908559e-09, 1.0875946e-09],\n",
       "       [1.1795041e-06, 4.8979149e-10, 2.9072463e-11, ..., 1.9401449e-11,\n",
       "        1.1148242e-04, 4.8751126e-08],\n",
       "       [9.7171311e-09, 1.5760673e-08, 5.0838898e-09, ..., 7.2510586e-15,\n",
       "        3.6665288e-08, 3.0370886e-10]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain vector of probabilities for each image\n",
    "predicted = new_model.predict(x_test)\n",
    "predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guess(predicted):\n",
    "    '''this method takes all predicted probabilities and returns the predicted classification for each image'''\n",
    "    guesses = []\n",
    "    for i in predicted:\n",
    "        guess = i.argmax()\n",
    "        guesses.append(guess)\n",
    "    return guesses\n",
    "\n",
    "guesses = get_guess(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes of correctly classified images\n",
    "correct = np.where(np.equal(guesses, y_test))\n",
    "correct = correct[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view examples of correctly classified numbers (function is defined below)\n",
    "#graph, pred, actual = correct_plot()\n",
    "\n",
    "# print('Predicted number:', pred)\n",
    "# print('Actual number:', actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes of misclassified images\n",
    "incorrect = np.where(np.not_equal(guesses, y_test))\n",
    "incorrect = incorrect[0].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view examples of misclassified numbers\n",
    "# graph, pred, actual = incorrect_plot()\n",
    "\n",
    "# print('Predicted number:', pred)\n",
    "# print('Actual number:', actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 9935\n",
      "Incorrect: 65\n"
     ]
    }
   ],
   "source": [
    "print('Correct:', len(correct))\n",
    "print('Incorrect:', len(incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the model perform on the MNIST test set? Give a detailed response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are common mix-ups of numbers in the network? Why? Is it possible to get to 100% accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anvil Uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload sample file for testing functions\n",
    "file = pd.read_csv('sample_data.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "anvil.server.connect(\"QFOHMQDBBF35GJCMIEXXISPD-QRBGHVVVOTAK7STL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media\n",
    "\n",
    "@anvil.server.callable\n",
    "def image_classifier(file):\n",
    "    '''this method takes an uploaded csv and classifies it 0-9'''\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        file = pd.read_csv(filename, header = None)\n",
    "\n",
    "    # first determine if grayscale values are normalized\n",
    "    if file.max().values.mean() > 1:\n",
    "        file = file / 255.0\n",
    "\n",
    "    # convert to np array, reshape to make tf happy\n",
    "    image = file.to_numpy().reshape(1, 28, 28, 1)\n",
    "\n",
    "    # load saved model\n",
    "    model = tf.keras.models.load_model('my_model')\n",
    "\n",
    "    # get probabilities of each number, choose index of highest one\n",
    "    predicted = model.predict(image).argmax()\n",
    "    \n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.mpl_util\n",
    "\n",
    "@anvil.server.callable\n",
    "def image_plot(file):\n",
    "    '''this method plots the user's uploaded csv'''\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        file = pd.read_csv(filename, header = None)\n",
    "   \n",
    "    # convert to np array\n",
    "    image = file.to_numpy()\n",
    "\n",
    "    # plot\n",
    "    plt.pcolor(1 - image[::-1, :], cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    return anvil.mpl_util.plot_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def incorrect_plot():\n",
    "    '''this method returns a random instance of an incorrectly labeled image along with pred/actual value'''\n",
    "    # choose random instance of incorrectly labeled image\n",
    "    i = random.choice(incorrect)\n",
    "\n",
    "    # plot\n",
    "    plt.pcolor(1-x_test[i,::-1,:] , cmap = 'gray' )\n",
    "    plt.axis('off')\n",
    "\n",
    "    # get predicted and actual number\n",
    "    pred = guesses[i]\n",
    "    actual = y_test[i] \n",
    "\n",
    "    return anvil.mpl_util.plot_image(), pred, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def correct_plot():\n",
    "    '''this method returns a random instance of an correctly labeled image along with pred/actual value'''\n",
    "    # choose random instance of correctly labeled image\n",
    "    i = random.choice(correct)\n",
    "\n",
    "    # plot\n",
    "    plt.pcolor(1-x_test[i,::-1,:] , cmap = 'gray' )\n",
    "    plt.axis('off')\n",
    "\n",
    "    # get predicted and actual number\n",
    "    pred = guesses[i]\n",
    "    actual = y_test[i] \n",
    "\n",
    "    return anvil.mpl_util.plot_image(), pred, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
